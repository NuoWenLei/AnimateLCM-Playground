{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66450aa7524644a8abd658c68d5f76aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c24b7ce3cb4ecf8e79956b59eab5ce",
              "IPY_MODEL_24ce9b2fdbdc4b4e9e56401cbbc22bf8",
              "IPY_MODEL_0b6a1a6fed094013a3a4c7d866d1a904"
            ],
            "layout": "IPY_MODEL_1239edf414eb4776ada68ee0735f722e"
          }
        },
        "37c24b7ce3cb4ecf8e79956b59eab5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623a88a7fe034d9c8b0e0e5044ba0d9b",
            "placeholder": "​",
            "style": "IPY_MODEL_c02bf4c1d9ac475cbf3073524203ffdb",
            "value": ""
          }
        },
        "24ce9b2fdbdc4b4e9e56401cbbc22bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24391096f2a44c3a9b333ad8657331d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e212d5449f24171af78f01ff029f231",
            "value": 0
          }
        },
        "0b6a1a6fed094013a3a4c7d866d1a904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5792529a7ed42bd874d409c0b00a40f",
            "placeholder": "​",
            "style": "IPY_MODEL_70334ff4d081419b86ececf9e287fe49",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "1239edf414eb4776ada68ee0735f722e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623a88a7fe034d9c8b0e0e5044ba0d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02bf4c1d9ac475cbf3073524203ffdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24391096f2a44c3a9b333ad8657331d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0e212d5449f24171af78f01ff029f231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5792529a7ed42bd874d409c0b00a40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70334ff4d081419b86ececf9e287fe49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea0cad95d50540d89e58aa200448cb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf594366ba6e4f4fa676468b8c36618f",
              "IPY_MODEL_dc0d7a3b4d954d44a0a4c12435a09558",
              "IPY_MODEL_3906ea47f78d4258b81368a541e23059"
            ],
            "layout": "IPY_MODEL_6b19c2fd59e74847a5ad837eec589494"
          }
        },
        "bf594366ba6e4f4fa676468b8c36618f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6609e7f4754b949e322ddf6ab4af0e",
            "placeholder": "​",
            "style": "IPY_MODEL_675cfb9846684303989ed16c2f9a5b76",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "dc0d7a3b4d954d44a0a4c12435a09558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f58db6ae5d4ae38913a6856484cbca",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_914ec10543a34287ad1bb9e2e8ac4166",
            "value": 6
          }
        },
        "3906ea47f78d4258b81368a541e23059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dac7e3b53174ecaa639e40876d9674f",
            "placeholder": "​",
            "style": "IPY_MODEL_227e99b32f734d9483f670f288d73a29",
            "value": " 6/6 [00:01&lt;00:00,  4.69it/s]"
          }
        },
        "6b19c2fd59e74847a5ad837eec589494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6609e7f4754b949e322ddf6ab4af0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675cfb9846684303989ed16c2f9a5b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5f58db6ae5d4ae38913a6856484cbca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "914ec10543a34287ad1bb9e2e8ac4166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dac7e3b53174ecaa639e40876d9674f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227e99b32f734d9483f670f288d73a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee0771f15c2548c98100131901f0aa4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3348c974f3934332ad0b8fd28fef213c",
              "IPY_MODEL_44bdf911ad1f4535b0fa3c90c5cf58ee",
              "IPY_MODEL_81a12462387f42b98259646f5cf07c26"
            ],
            "layout": "IPY_MODEL_e083edcf7d7346f6a80015c12b623896"
          }
        },
        "3348c974f3934332ad0b8fd28fef213c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ead1d32e7d4d35ba907c3c7cc68d4b",
            "placeholder": "​",
            "style": "IPY_MODEL_0254eba2e6a549c6aea4a6303abe33f7",
            "value": "100%"
          }
        },
        "44bdf911ad1f4535b0fa3c90c5cf58ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb25fe90bd74f96a62f87d12e5ab94b",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2655b29167c4cc7b3ab81e9c4c264d4",
            "value": 6
          }
        },
        "81a12462387f42b98259646f5cf07c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe7276e84024470adecc7919b669ed7",
            "placeholder": "​",
            "style": "IPY_MODEL_50349a9f052b4ff2b339469dd3be6bf9",
            "value": " 6/6 [00:04&lt;00:00,  1.72it/s]"
          }
        },
        "e083edcf7d7346f6a80015c12b623896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ead1d32e7d4d35ba907c3c7cc68d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0254eba2e6a549c6aea4a6303abe33f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb25fe90bd74f96a62f87d12e5ab94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2655b29167c4cc7b3ab81e9c4c264d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fe7276e84024470adecc7919b669ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50349a9f052b4ff2b339469dd3be6bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBR_FmEbYAX7",
        "outputId": "ea11e063-59d2-466e-f061-f9796448e5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.26.3\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZKBCCQFZoa9",
        "outputId": "4f4f7677-68e6-4a81-d2cd-6017aafebb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft\n",
            "  Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m184.3/190.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: accelerate, peft\n",
            "Successfully installed accelerate-0.27.2 peft-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from typing import Any, Callable, Dict, List, Optional, Union\n",
        "from diffusers import AnimateDiffPipeline, LCMScheduler, MotionAdapter\n",
        "from diffusers.pipelines.animatediff import AnimateDiffPipelineOutput\n",
        "from diffusers.image_processor import PipelineImageInput\n",
        "from diffusers.utils import (USE_PEFT_BACKEND,\n",
        "    deprecate,\n",
        "    logging,\n",
        "    replace_example_docstring,\n",
        "    scale_lora_layers,\n",
        "    unscale_lora_layers,\n",
        "    export_to_gif)"
      ],
      "metadata": {
        "id": "Vg48RHAiYLk3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "66450aa7524644a8abd658c68d5f76aa",
            "37c24b7ce3cb4ecf8e79956b59eab5ce",
            "24ce9b2fdbdc4b4e9e56401cbbc22bf8",
            "0b6a1a6fed094013a3a4c7d866d1a904",
            "1239edf414eb4776ada68ee0735f722e",
            "623a88a7fe034d9c8b0e0e5044ba0d9b",
            "c02bf4c1d9ac475cbf3073524203ffdb",
            "24391096f2a44c3a9b333ad8657331d7",
            "0e212d5449f24171af78f01ff029f231",
            "b5792529a7ed42bd874d409c0b00a40f",
            "70334ff4d081419b86ececf9e287fe49"
          ]
        },
        "outputId": "dd4da6ba-9c21-484e-9d71-14b92ac3d8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66450aa7524644a8abd658c68d5f76aa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taken from: https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/animatediff/pipeline_animatediff.py\n",
        "logger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n",
        "\n",
        "EXAMPLE_DOC_STRING = \"\"\"\n",
        "    Examples:\n",
        "        ```py\n",
        "        >>> import torch\n",
        "        >>> from diffusers import MotionAdapter, AnimateDiffPipeline, DDIMScheduler\n",
        "        >>> from diffusers.utils import export_to_gif\n",
        "\n",
        "        >>> adapter = MotionAdapter.from_pretrained(\"guoyww/animatediff-motion-adapter-v1-5-2\")\n",
        "        >>> pipe = AnimateDiffPipeline.from_pretrained(\"frankjoshua/toonyou_beta6\", motion_adapter=adapter)\n",
        "        >>> pipe.scheduler = DDIMScheduler(beta_schedule=\"linear\", steps_offset=1, clip_sample=False)\n",
        "        >>> output = pipe(prompt=\"A corgi walking in the park\")\n",
        "        >>> frames = output.frames[0]\n",
        "        >>> export_to_gif(frames, \"animation.gif\")\n",
        "        ```\n",
        "\"\"\"\n",
        "\n",
        "def tensor2vid(video: torch.Tensor, processor: \"VaeImageProcessor\", output_type: str = \"np\"):\n",
        "    batch_size, channels, num_frames, height, width = video.shape\n",
        "    outputs = []\n",
        "    for batch_idx in range(batch_size):\n",
        "        batch_vid = video[batch_idx].permute(1, 0, 2, 3)\n",
        "        batch_output = processor.postprocess(batch_vid, output_type)\n",
        "\n",
        "        outputs.append(batch_output)\n",
        "\n",
        "    if output_type == \"np\":\n",
        "        outputs = np.stack(outputs)\n",
        "\n",
        "    elif output_type == \"pt\":\n",
        "        outputs = torch.stack(outputs)\n",
        "\n",
        "    elif not output_type == \"pil\":\n",
        "        raise ValueError(f\"{output_type} does not exist. Please choose one of ['np', 'pt', 'pil]\")\n",
        "\n",
        "    return outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "ThYokNAyv5Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified from: https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/animatediff/pipeline_animatediff.py\n",
        "# Extends AnimateDiffPipeline to add returning intermediate frames\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ModifiedAnimateDiffPipeline(AnimateDiffPipeline):\n",
        "\n",
        "    def check_inputs(\n",
        "        self,\n",
        "        prompt,\n",
        "        height,\n",
        "        width,\n",
        "        callback_steps,\n",
        "        negative_prompt=None,\n",
        "        prompt_embeds=None,\n",
        "        negative_prompt_embeds=None,\n",
        "        ip_adapter_image=None,\n",
        "        ip_adapter_image_embeds=None,\n",
        "        callback_on_step_end_tensor_inputs=None,\n",
        "    ):\n",
        "        if height % 8 != 0 or width % 8 != 0:\n",
        "            raise ValueError(f\"`height` and `width` have to be divisible by 8 but are {height} and {width}.\")\n",
        "\n",
        "        if callback_steps is not None and (not isinstance(callback_steps, int) or callback_steps <= 0):\n",
        "            raise ValueError(\n",
        "                f\"`callback_steps` has to be a positive integer but is {callback_steps} of type\"\n",
        "                f\" {type(callback_steps)}.\"\n",
        "            )\n",
        "        if callback_on_step_end_tensor_inputs is not None and not all(\n",
        "            k in self._callback_tensor_inputs for k in callback_on_step_end_tensor_inputs\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                f\"`callback_on_step_end_tensor_inputs` has to be in {self._callback_tensor_inputs}, but found {[k for k in callback_on_step_end_tensor_inputs if k not in self._callback_tensor_inputs]}\"\n",
        "            )\n",
        "\n",
        "        if prompt is not None and prompt_embeds is not None:\n",
        "            raise ValueError(\n",
        "                f\"Cannot forward both `prompt`: {prompt} and `prompt_embeds`: {prompt_embeds}. Please make sure to\"\n",
        "                \" only forward one of the two.\"\n",
        "            )\n",
        "        elif prompt is None and prompt_embeds is None:\n",
        "            raise ValueError(\n",
        "                \"Provide either `prompt` or `prompt_embeds`. Cannot leave both `prompt` and `prompt_embeds` undefined.\"\n",
        "            )\n",
        "        elif prompt is not None and (not isinstance(prompt, str) and not isinstance(prompt, list)):\n",
        "            raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\n",
        "\n",
        "        if negative_prompt is not None and negative_prompt_embeds is not None:\n",
        "            raise ValueError(\n",
        "                f\"Cannot forward both `negative_prompt`: {negative_prompt} and `negative_prompt_embeds`:\"\n",
        "                f\" {negative_prompt_embeds}. Please make sure to only forward one of the two.\"\n",
        "            )\n",
        "\n",
        "        if prompt_embeds is not None and negative_prompt_embeds is not None:\n",
        "            if prompt_embeds.shape != negative_prompt_embeds.shape:\n",
        "                raise ValueError(\n",
        "                    \"`prompt_embeds` and `negative_prompt_embeds` must have the same shape when passed directly, but\"\n",
        "                    f\" got: `prompt_embeds` {prompt_embeds.shape} != `negative_prompt_embeds`\"\n",
        "                    f\" {negative_prompt_embeds.shape}.\"\n",
        "                )\n",
        "\n",
        "        if ip_adapter_image is not None and ip_adapter_image_embeds is not None:\n",
        "            raise ValueError(\n",
        "                \"Provide either `ip_adapter_image` or `ip_adapter_image_embeds`. Cannot leave both `ip_adapter_image` and `ip_adapter_image_embeds` defined.\"\n",
        "            )\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    @replace_example_docstring(EXAMPLE_DOC_STRING)\n",
        "    def __call__(\n",
        "        self,\n",
        "        prompt: Union[str, List[str]] = None,\n",
        "        num_frames: Optional[int] = 16,\n",
        "        height: Optional[int] = None,\n",
        "        width: Optional[int] = None,\n",
        "        num_inference_steps: int = 50,\n",
        "        guidance_scale: float = 7.5,\n",
        "        negative_prompt: Optional[Union[str, List[str]]] = None,\n",
        "        num_videos_per_prompt: Optional[int] = 1,\n",
        "        eta: float = 0.0,\n",
        "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
        "        latents: Optional[torch.FloatTensor] = None,\n",
        "        prompt_embeds: Optional[torch.FloatTensor] = None,\n",
        "        negative_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
        "        ip_adapter_image: Optional[PipelineImageInput] = None,\n",
        "        ip_adapter_image_embeds: Optional[List[torch.FloatTensor]] = None,\n",
        "        output_type: Optional[str] = \"pil\",\n",
        "        return_dict: bool = True,\n",
        "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
        "        clip_skip: Optional[int] = None,\n",
        "        callback_on_step_end: Optional[Callable[[int, int, Dict], None]] = None,\n",
        "        callback_on_step_end_tensor_inputs: List[str] = [\"latents\"],\n",
        "\n",
        "        # New argument\n",
        "        return_intermediate_frames = False,\n",
        "\n",
        "        **kwargs,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        The call function to the pipeline for generation.\n",
        "\n",
        "        Args:\n",
        "            prompt (`str` or `List[str]`, *optional*):\n",
        "                The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.\n",
        "            height (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):\n",
        "                The height in pixels of the generated video.\n",
        "            width (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):\n",
        "                The width in pixels of the generated video.\n",
        "            num_frames (`int`, *optional*, defaults to 16):\n",
        "                The number of video frames that are generated. Defaults to 16 frames which at 8 frames per seconds\n",
        "                amounts to 2 seconds of video.\n",
        "            num_inference_steps (`int`, *optional*, defaults to 50):\n",
        "                The number of denoising steps. More denoising steps usually lead to a higher quality videos at the\n",
        "                expense of slower inference.\n",
        "            guidance_scale (`float`, *optional*, defaults to 7.5):\n",
        "                A higher guidance scale value encourages the model to generate images closely linked to the text\n",
        "                `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale > 1`.\n",
        "            negative_prompt (`str` or `List[str]`, *optional*):\n",
        "                The prompt or prompts to guide what to not include in image generation. If not defined, you need to\n",
        "                pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale < 1`).\n",
        "            eta (`float`, *optional*, defaults to 0.0):\n",
        "                Corresponds to parameter eta (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies\n",
        "                to the [`~schedulers.DDIMScheduler`], and is ignored in other schedulers.\n",
        "            generator (`torch.Generator` or `List[torch.Generator]`, *optional*):\n",
        "                A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make\n",
        "                generation deterministic.\n",
        "            latents (`torch.FloatTensor`, *optional*):\n",
        "                Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for video\n",
        "                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents\n",
        "                tensor is generated by sampling using the supplied random `generator`. Latents should be of shape\n",
        "                `(batch_size, num_channel, num_frames, height, width)`.\n",
        "            prompt_embeds (`torch.FloatTensor`, *optional*):\n",
        "                Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not\n",
        "                provided, text embeddings are generated from the `prompt` input argument.\n",
        "            negative_prompt_embeds (`torch.FloatTensor`, *optional*):\n",
        "                Pre-generated negative text embeddings. Can be used to easily tweak text inputs (prompt weighting). If\n",
        "                not provided, `negative_prompt_embeds` are generated from the `negative_prompt` input argument.\n",
        "            ip_adapter_image: (`PipelineImageInput`, *optional*):\n",
        "                Optional image input to work with IP Adapters.\n",
        "            ip_adapter_image_embeds (`List[torch.FloatTensor]`, *optional*):\n",
        "                Pre-generated image embeddings for IP-Adapter. If not\n",
        "                provided, embeddings are computed from the `ip_adapter_image` input argument.\n",
        "            output_type (`str`, *optional*, defaults to `\"pil\"`):\n",
        "                The output format of the generated video. Choose between `torch.FloatTensor`, `PIL.Image` or\n",
        "                `np.array`.\n",
        "            return_dict (`bool`, *optional*, defaults to `True`):\n",
        "                Whether or not to return a [`~pipelines.text_to_video_synthesis.TextToVideoSDPipelineOutput`] instead\n",
        "                of a plain tuple.\n",
        "            cross_attention_kwargs (`dict`, *optional*):\n",
        "                A kwargs dictionary that if specified is passed along to the [`AttentionProcessor`] as defined in\n",
        "                [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).\n",
        "            clip_skip (`int`, *optional*):\n",
        "                Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that\n",
        "                the output of the pre-final layer will be used for computing the prompt embeddings.\n",
        "            callback_on_step_end (`Callable`, *optional*):\n",
        "                A function that calls at the end of each denoising steps during the inference. The function is called\n",
        "                with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,\n",
        "                callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by\n",
        "                `callback_on_step_end_tensor_inputs`.\n",
        "            callback_on_step_end_tensor_inputs (`List`, *optional*):\n",
        "                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list\n",
        "                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the\n",
        "                `._callback_tensor_inputs` attribute of your pipeine class.\n",
        "\n",
        "        Examples:\n",
        "\n",
        "        Returns:\n",
        "            [`~pipelines.text_to_video_synthesis.TextToVideoSDPipelineOutput`] or `tuple`:\n",
        "                If `return_dict` is `True`, [`~pipelines.text_to_video_synthesis.TextToVideoSDPipelineOutput`] is\n",
        "                returned, otherwise a `tuple` is returned where the first element is a list with the generated frames.\n",
        "        \"\"\"\n",
        "\n",
        "        callback = kwargs.pop(\"callback\", None)\n",
        "        callback_steps = kwargs.pop(\"callback_steps\", None)\n",
        "\n",
        "        if callback is not None:\n",
        "            deprecate(\n",
        "                \"callback\",\n",
        "                \"1.0.0\",\n",
        "                \"Passing `callback` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`\",\n",
        "            )\n",
        "        if callback_steps is not None:\n",
        "            deprecate(\n",
        "                \"callback_steps\",\n",
        "                \"1.0.0\",\n",
        "                \"Passing `callback_steps` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`\",\n",
        "            )\n",
        "\n",
        "        # 0. Default height and width to unet\n",
        "        height = height or self.unet.config.sample_size * self.vae_scale_factor\n",
        "        width = width or self.unet.config.sample_size * self.vae_scale_factor\n",
        "\n",
        "        num_videos_per_prompt = 1\n",
        "\n",
        "        # 1. Check inputs. Raise error if not correct\n",
        "        self.check_inputs(\n",
        "            prompt,\n",
        "            height,\n",
        "            width,\n",
        "            callback_steps,\n",
        "            negative_prompt,\n",
        "            prompt_embeds,\n",
        "            negative_prompt_embeds,\n",
        "            ip_adapter_image,\n",
        "            ip_adapter_image_embeds,\n",
        "            callback_on_step_end_tensor_inputs,\n",
        "        )\n",
        "\n",
        "        self._guidance_scale = guidance_scale\n",
        "        self._clip_skip = clip_skip\n",
        "        self._cross_attention_kwargs = cross_attention_kwargs\n",
        "\n",
        "        # 2. Define call parameters\n",
        "        if prompt is not None and isinstance(prompt, str):\n",
        "            batch_size = 1\n",
        "        elif prompt is not None and isinstance(prompt, list):\n",
        "            batch_size = len(prompt)\n",
        "        else:\n",
        "            batch_size = prompt_embeds.shape[0]\n",
        "\n",
        "        device = self._execution_device\n",
        "\n",
        "        # 3. Encode input prompt\n",
        "        text_encoder_lora_scale = (\n",
        "            self.cross_attention_kwargs.get(\"scale\", None) if self.cross_attention_kwargs is not None else None\n",
        "        )\n",
        "        prompt_embeds, negative_prompt_embeds = self.encode_prompt(\n",
        "            prompt,\n",
        "            device,\n",
        "            num_videos_per_prompt,\n",
        "            self.do_classifier_free_guidance,\n",
        "            negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            lora_scale=text_encoder_lora_scale,\n",
        "            clip_skip=self.clip_skip,\n",
        "        )\n",
        "        # For classifier free guidance, we need to do two forward passes.\n",
        "        # Here we concatenate the unconditional and text embeddings into a single batch\n",
        "        # to avoid doing two forward passes\n",
        "        if self.do_classifier_free_guidance:\n",
        "            prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])\n",
        "\n",
        "        if ip_adapter_image is not None or ip_adapter_image_embeds is not None:\n",
        "            image_embeds = self.prepare_ip_adapter_image_embeds(\n",
        "                ip_adapter_image, ip_adapter_image_embeds, device, batch_size * num_videos_per_prompt\n",
        "            )\n",
        "\n",
        "        # 4. Prepare timesteps\n",
        "        self.scheduler.set_timesteps(num_inference_steps, device=device)\n",
        "        timesteps = self.scheduler.timesteps\n",
        "\n",
        "        # 5. Prepare latent variables\n",
        "        num_channels_latents = self.unet.config.in_channels\n",
        "        latents = self.prepare_latents(\n",
        "            batch_size * num_videos_per_prompt,\n",
        "            num_channels_latents,\n",
        "            num_frames,\n",
        "            height,\n",
        "            width,\n",
        "            prompt_embeds.dtype,\n",
        "            device,\n",
        "            generator,\n",
        "            latents,\n",
        "        )\n",
        "\n",
        "        # 6. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline\n",
        "        extra_step_kwargs = self.prepare_extra_step_kwargs(generator, eta)\n",
        "\n",
        "        # 7. Add image embeds for IP-Adapter\n",
        "        added_cond_kwargs = (\n",
        "            {\"image_embeds\": image_embeds}\n",
        "            if ip_adapter_image is not None or ip_adapter_image_embeds is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        intermediate_latents = []\n",
        "\n",
        "        num_free_init_iters = self._free_init_num_iters if self.free_init_enabled else 1\n",
        "        for free_init_iter in range(num_free_init_iters):\n",
        "            if self.free_init_enabled:\n",
        "                latents, timesteps = self._apply_free_init(\n",
        "                    latents, free_init_iter, num_inference_steps, device, latents.dtype, generator\n",
        "                )\n",
        "\n",
        "            self._num_timesteps = len(timesteps)\n",
        "            num_warmup_steps = len(timesteps) - num_inference_steps * self.scheduler.order\n",
        "            with self.progress_bar(total=num_inference_steps) as progress_bar:\n",
        "                for i, t in enumerate(timesteps):\n",
        "                    # expand the latents if we are doing classifier free guidance\n",
        "                    latent_model_input = torch.cat([latents] * 2) if self.do_classifier_free_guidance else latents\n",
        "                    latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "                    # predict the noise residual\n",
        "                    noise_pred = self.unet(\n",
        "                        latent_model_input,\n",
        "                        t,\n",
        "                        encoder_hidden_states=prompt_embeds,\n",
        "                        cross_attention_kwargs=cross_attention_kwargs,\n",
        "                        added_cond_kwargs=added_cond_kwargs,\n",
        "                    ).sample\n",
        "\n",
        "                    # perform guidance\n",
        "                    if self.do_classifier_free_guidance:\n",
        "                        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "                        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "                    # compute the previous noisy sample x_t -> x_t-1\n",
        "                    latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs).prev_sample\n",
        "\n",
        "                    intermediate_latents.append(latents)\n",
        "\n",
        "                    if callback_on_step_end is not None:\n",
        "                        callback_kwargs = {}\n",
        "                        for k in callback_on_step_end_tensor_inputs:\n",
        "                            callback_kwargs[k] = locals()[k]\n",
        "                        callback_outputs = callback_on_step_end(self, i, t, callback_kwargs)\n",
        "\n",
        "                        latents = callback_outputs.pop(\"latents\", latents)\n",
        "                        prompt_embeds = callback_outputs.pop(\"prompt_embeds\", prompt_embeds)\n",
        "                        negative_prompt_embeds = callback_outputs.pop(\"negative_prompt_embeds\", negative_prompt_embeds)\n",
        "\n",
        "                    # call the callback, if provided\n",
        "                    if i == len(timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % self.scheduler.order == 0):\n",
        "                        progress_bar.update()\n",
        "                        if callback is not None and i % callback_steps == 0:\n",
        "                            callback(i, t, latents)\n",
        "\n",
        "        if output_type == \"latent\":\n",
        "            return AnimateDiffPipelineOutput(frames=latents)\n",
        "\n",
        "        video_tensor = self.decode_latents(latents)\n",
        "        video = tensor2vid(video_tensor, self.image_processor, output_type=output_type)\n",
        "\n",
        "        # 9. Offload all models\n",
        "        self.maybe_free_model_hooks()\n",
        "\n",
        "        if not return_dict:\n",
        "            return (video,)\n",
        "\n",
        "        if return_intermediate_frames:\n",
        "          video_tensor_results = []\n",
        "          for intermediates in tqdm(intermediate_latents):\n",
        "            video_tensor_results.append(self.decode_latents(intermediates))\n",
        "          # video = tensor2vid(video_tensor, self.image_processor, output_type=output_type)\n",
        "          return AnimateDiffPipelineOutput(frames=video), intermediate_latents, video_tensor_results\n",
        "\n",
        "        return AnimateDiffPipelineOutput(frames=video)"
      ],
      "metadata": {
        "id": "y3d7N__SvymX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter = MotionAdapter.from_pretrained(\"wangfuyun/AnimateLCM\", torch_dtype=torch.float16)\n",
        "pipe = ModifiedAnimateDiffPipeline.from_pretrained(\"emilianJR/epiCRealism\", motion_adapter=adapter, torch_dtype=torch.float16)\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, beta_schedule=\"linear\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "ea0cad95d50540d89e58aa200448cb2b",
            "bf594366ba6e4f4fa676468b8c36618f",
            "dc0d7a3b4d954d44a0a4c12435a09558",
            "3906ea47f78d4258b81368a541e23059",
            "6b19c2fd59e74847a5ad837eec589494",
            "8a6609e7f4754b949e322ddf6ab4af0e",
            "675cfb9846684303989ed16c2f9a5b76",
            "f5f58db6ae5d4ae38913a6856484cbca",
            "914ec10543a34287ad1bb9e2e8ac4166",
            "7dac7e3b53174ecaa639e40876d9674f",
            "227e99b32f734d9483f670f288d73a29"
          ]
        },
        "id": "Wx2ASy3ivwUl",
        "outputId": "1c929f11-ba52-43bc-8806-477115cd64d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea0cad95d50540d89e58aa200448cb2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "The config attributes {'center_input_sample': False, 'flip_sin_to_cos': True, 'freq_shift': 0, 'mid_block_type': 'UNetMidBlock2DCrossAttn', 'only_cross_attention': False, 'attention_head_dim': 8, 'dual_cross_attention': False, 'class_embed_type': None, 'addition_embed_type': None, 'num_class_embeds': None, 'upcast_attention': False, 'resnet_time_scale_shift': 'default', 'resnet_skip_time_act': False, 'resnet_out_scale_factor': 1.0, 'time_embedding_type': 'positional', 'time_embedding_dim': None, 'time_embedding_act_fn': None, 'timestep_post_act': None, 'time_cond_proj_dim': None, 'conv_in_kernel': 3, 'conv_out_kernel': 3, 'projection_class_embeddings_input_dim': None, 'class_embeddings_concat': False, 'mid_block_only_cross_attention': None, 'cross_attention_norm': None, 'addition_embed_type_num_heads': 64} were passed to UNetMotionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.load_lora_weights(\"wangfuyun/AnimateLCM\", weight_name=\"AnimateLCM_sd15_t2v_lora.safetensors\", adapter_name=\"lcm-lora\")\n",
        "pipe.set_adapters([\"lcm-lora\"], [0.8])\n",
        "\n",
        "pipe.enable_vae_slicing()\n",
        "pipe.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "eDEGTe_yYV3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output, intermediate_latents, intermediate_videos = pipe(\n",
        "    prompt=\"A space rocket with trails of smoke behind it launching into space from the desert, 4k, high resolution\",\n",
        "    negative_prompt=\"bad quality, worse quality, low resolution\",\n",
        "    num_frames=16,\n",
        "    guidance_scale=2.0,\n",
        "    num_inference_steps=6,\n",
        "    generator=torch.Generator(\"cpu\").manual_seed(0),\n",
        "    return_intermediate_frames = True\n",
        ")\n",
        "frames = output.frames[0]\n",
        "export_to_gif(frames, \"animatelcm.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "ee0771f15c2548c98100131901f0aa4e",
            "3348c974f3934332ad0b8fd28fef213c",
            "44bdf911ad1f4535b0fa3c90c5cf58ee",
            "81a12462387f42b98259646f5cf07c26",
            "e083edcf7d7346f6a80015c12b623896",
            "b9ead1d32e7d4d35ba907c3c7cc68d4b",
            "0254eba2e6a549c6aea4a6303abe33f7",
            "efb25fe90bd74f96a62f87d12e5ab94b",
            "c2655b29167c4cc7b3ab81e9c4c264d4",
            "2fe7276e84024470adecc7919b669ed7",
            "50349a9f052b4ff2b339469dd3be6bf9"
          ]
        },
        "id": "2cwlYZBkY5xz",
        "outputId": "3f08296a-09e5-4624-867d-e7cd34887516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee0771f15c2548c98100131901f0aa4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'animatelcm.gif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(intermediate_latents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGZISaXPaPie",
        "outputId": "5cd946f3-16ea-4a0d-8168-d9914f632738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_0 = tensor2vid(intermediate_videos[0], pipe.image_processor, output_type=\"pil\")"
      ],
      "metadata": {
        "id": "c6pF3jxI0rEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_to_gif(video_0[0], \"animatelcm_0.gif\")"
      ],
      "metadata": {
        "id": "fqzC6tYRv8Dg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58d4a121-68c7-456e-cf94-f45d647ab58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'animatelcm_0.gif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, vid_tensor in tqdm(enumerate(intermediate_videos)):\n",
        "  vid = tensor2vid(vid_tensor, pipe.image_processor, output_type=\"pil\")\n",
        "  export_to_gif(vid[0], f\"animatelcm_{i}.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPwlzyrIN9jb",
        "outputId": "ae572a51-bc12-467e-b70e-19a0463cefe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6it [00:20,  3.34s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Must sample inside torch no_grad function to avoid absurd memory allocations\n",
        "@torch.no_grad()\n",
        "def latents_to_video(latent):\n",
        "  vid_tensor = pipe.decode_latents(latent)\n",
        "  vid = tensor2vid(vid_tensor, pipe.image_processor, output_type=\"pil\")[0]\n",
        "  export_to_gif(vid, \"from_function.gif\")"
      ],
      "metadata": {
        "id": "4oTyhzGHNn83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latents_to_video(intermediate_latents[0])"
      ],
      "metadata": {
        "id": "6vVmVO9vOZDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taken from here: https://stackoverflow.com/questions/51517685/combine-several-gif-horizontally-python\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "#Create reader object for the gif\n",
        "\n",
        "num_gifs = len(intermediate_latents)\n",
        "gifs = []\n",
        "for i in range(6):\n",
        "  gifs.append(imageio.get_reader(f\"animatelcm_{i}.gif\"))\n",
        "\n",
        "#If they don't have the same number of frame take the shorter\n",
        "number_of_frames = min([gif.get_length() for gif in gifs]) - 1\n",
        "\n",
        "print(number_of_frames)\n",
        "\n",
        "#Create writer object\n",
        "new_gif = imageio.get_writer('output.gif')\n",
        "\n",
        "for frame_number in range(number_of_frames):\n",
        "    ims = []\n",
        "    for i in range(len(gifs)):\n",
        "      ims.append(gifs[i].get_next_data())\n",
        "    #here is the magic\n",
        "    new_image = np.hstack(ims)\n",
        "    new_gif.append_data(new_image)\n",
        "\n",
        "for i in range(len(gifs)):\n",
        "  gifs[i].close()\n",
        "new_gif.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYK72TgLObdJ",
        "outputId": "40b8128a-1f4b-407d-8c96-29bd6c22c403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBIl5MshQrX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}